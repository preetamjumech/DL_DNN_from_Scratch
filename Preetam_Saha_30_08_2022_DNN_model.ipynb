{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preetam_Saha_30.08.2022_DNN_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMZFq2fRj/1wnU6wFI89ZP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preetamjumech/DL_DNN_from_Sctrach/blob/main/Preetam_Saha_30_08_2022_DNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwT6Tkl6MPZ9",
        "outputId": "168cfa6c-bc61-49d0-885e-18a6a26bd5b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-30 08:10:17--  https://github.com/MorvanZhou/PyTorch-Tutorial/raw/master/tutorial-contents-notebooks/mnist/processed/training.pt\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/MorvanZhou/PyTorch-Tutorial/master/tutorial-contents-notebooks/mnist/processed/training.pt [following]\n",
            "--2022-08-30 08:10:17--  https://raw.githubusercontent.com/MorvanZhou/PyTorch-Tutorial/master/tutorial-contents-notebooks/mnist/processed/training.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47520431 (45M) [application/octet-stream]\n",
            "Saving to: ‘training.pt.1’\n",
            "\n",
            "training.pt.1       100%[===================>]  45.32M   203MB/s    in 0.2s    \n",
            "\n",
            "2022-08-30 08:10:17 (203 MB/s) - ‘training.pt.1’ saved [47520431/47520431]\n",
            "\n",
            "--2022-08-30 08:10:17--  https://github.com/MorvanZhou/PyTorch-Tutorial/raw/master/tutorial-contents-notebooks/mnist/processed/test.pt\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/MorvanZhou/PyTorch-Tutorial/master/tutorial-contents-notebooks/mnist/processed/test.pt [following]\n",
            "--2022-08-30 08:10:17--  https://raw.githubusercontent.com/MorvanZhou/PyTorch-Tutorial/master/tutorial-contents-notebooks/mnist/processed/test.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7920431 (7.6M) [application/octet-stream]\n",
            "Saving to: ‘test.pt.1’\n",
            "\n",
            "test.pt.1           100%[===================>]   7.55M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-08-30 08:10:18 (89.7 MB/s) - ‘test.pt.1’ saved [7920431/7920431]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#.pt means pytorch files (dump of data here both .pt files, just to import those data by torch.load)\n",
        "!wget https://github.com/MorvanZhou/PyTorch-Tutorial/raw/master/tutorial-contents-notebooks/mnist/processed/training.pt\n",
        "!wget https://github.com/MorvanZhou/PyTorch-Tutorial/raw/master/tutorial-contents-notebooks/mnist/processed/test.pt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensors and arrays are interchangable\n",
        "#only some extra functions are added to the tensors, some computational graphs are avl to the tensors\n"
      ],
      "metadata": {
        "id": "NPLXwHBMN4z2"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "GcxHlYQhOOCV"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = torch.load(\"training.pt\") #tuple"
      ],
      "metadata": {
        "id": "GdY9SH7HOOE8"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape #multidimensional tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le67kWEyOOIi",
        "outputId": "61e3b92c-a9d6-4804-9522-8d9d8b50c562"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "7A8pWNb9PnUP"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "  plt.subplot(2,10,i+1)\n",
        "  plt.imshow(x_train[i].numpy()) #cv2_imshow is applicable to numpy, so converting tensors to numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "5QEwaZhZP-CB",
        "outputId": "1285a46d-5f52-4432-ef18-0b3542dcc838"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 20 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC1CAYAAABPoAT2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3gc1b3/8feZ2aaVVr33LkvuvWOMwRQDhoABE3oNBALJvSG5yS/3htx0EgjhJiQUA6EZgg2mF9vY2Lj3KhfJktV7L1tmzu8P2caAbWxpV1aU83qefR5t0ZyPVqPvzpxz5khIKVEURVH+9WlnO4CiKIriH6qgK4qiDBKqoCuKogwSqqAriqIMEqqgK4qiDBKqoCuKogwSfSroQoiLhBD7hBAHhRA/9lcolWNw5BhIWVQOleNfIUefSSl7dQN0oAjIBGzAdqCgt9tTOQZXjoGUReVQOf4Vcvjj1pcj9AnAQSllsZTSAywE5vZheyrH4MoxkLKoHCrHv0KOPhNHPqHO/BuFuBq4SEp5x5H7NwITpZT3feV1dwF3AejoY52E9i3xV3jxYODFQfCR+24MDBw46aYDj3QLlaP/c5wqC8gBkcOBkzaa6qWUMSqHynG2c5zK0Rzf9LqAF/TjhYpIOVHM6lV7J1Mjy2mgmgIxDoAqWUoLjQwRo1kvl9EqG4XK0f85TpWlhcYBkWOIGM1S+cZmKeU4lUPlONs5TuVEOU6kL10uFUDKcfeTjzzWr+wE0U3XsfvddGEnqL9jqBwDOIvKoXL8K+Twh74U9I1AjhAiQwhhA64D3vZPrNMXSgRdtNMlOzClSQ1lxJAQsPYsKcnU3TMZ/dNELt3dRNEfJiFGD+33HCczUHIMpCz/Ljka7pxM+oYgbtpXRvHvJ2OJjzsrOU6XyvFllpRkWJZM47u5vd9Gb79RSukTQtwHfETPKPECKeXuXic5ESHQXS4IcgDQNSqVinOteMMM9C6N9Hc8NHy/k1/Uf84jD39KU2swqU3JhIgwv8Y4ypKWwr77kllw1ZMUWDtwCJ3zr97LfaOuw3K+Rp4cxVZWIZEkkh6wHCejR0RQP28IE/Pa2PDj9UiPu19zaMOGUPj9EF6a+RRL24ax6sFJ5C2v+fp70s8LfGqi/343wm5HCw/Dm5tEzfggrO2SmBe2IN3ugOawJCXSPLOLn8Z/QrRm49H8BoyUWKiu+dprA5ojPRUjwkVrnovu65v467BXMPhy71qhO5Fffno5eQ9sI88TwN+LpqMNy6Ho+gjs9YLEP6w58cv6cf84GUtyEnt+EccbmU8y77PvENnb7fQlhJTyfeD9vmzjeJaUZGRIEC3DIqkbo+FL8DArv5CrolYC4NK6iNS6aZNW3m4Zw4qhObxT8A/aTJ1NQ27k8GO5BL+x3l9xvkTPzqDwu3H85bIFTLR76TQFZT4TgIvid/PJ5GnEbLIR7e39J7tv1li6oq2EvbsTs6PjjL9fhLloyZVoeeOZVjAJc/veXmc5U3peNvtuD+fN8x4n36ZR7StnpVUjWiQQfZbOEI4X6Bx6XCy1l2bRfmE7c3N2cnHoUsK1LpZ35PNs1EUk/2ZNQHOYzS3oh9JYNy6JK4MbsVkMTIvG1wYqjvB3Dj0vm7LLYom9qJxpMdsYGlTOdEcF0XoQX/0EH207TNLsF7jvN7eS+8sgopsD83vRQ0PYe28oz13wd2778E70iAiMpqYTvvZs7qeWjDT2/DiWJTOfoM4IJnydvffb8mOuPtFG5tPxSBc3pqwiydpEjN6GS/MSowlCtON/QDt/aspl8aLpWDrhwpUP4ayRBFf5cK3eg+nnXMJuR+RlUHh3GI/OfolzHG1o6JQZGv9RNI+DJXFsnP047X9zsOSZGcQ9ceKjgNNROdWOO7ubiJUhvSro0unAktpBWlgjHSK21zl6w4hw4khtI9d6shLif3puFlWz42ib0sms7H2MDjnMK2UTaFuSgDAlXbGCtPdbkZt2BSyDJS2FistTiLi8gv9Of4GhtloMBIWeGDxS55rQHSy/MA9zURbG/qKA5TA7OwmqFhzsjofgxoC1czIHb43h/sve40rXboKFhl1YsIqefmjzK3+VuhBMc7Tw0Jy3+eeSC9FWbQ1MKKGhu7xMdXixx3ZCVDicpKCfTUZ4CLNH7yJG8/HDoouJX1iI0cttDZyC3tBKpMPDZSFFRGgOenpxdADWunU+bBlBlqOWuSFFvF81jIyni5DGkR3F7UZ6PJjd3X7PVXP7WNKuLeKVlJcZZvNiFVYA0iyS/LBqSuuSeal1KNeEbeIfw6Zw4l7L0zP+4l3sqksAceZFUdjttA2J4PejX+QHG64lZ/++PiQ5M5aUZIovDOEPIxdQb3r4SfmllP4hD9f2Q73eMb+JOX00B++Cn4xbzJSgYop9kWzvTOPe9BU4vu8FoNYXyiMhc8nc5P/2NZeL6puHE3Z5JT9Oe5UpQWXE6XaKvRrXbL2D0FdDqRkv2H39n5kRvZ+P485B2+//HMfyOJ10xUuyHdWBa+QUnJUCq/ARo9up9Ln5WcVsNpalAiAlRIV1cEf659wQWgaAVehk2Wow7FrA1x+xCh2LxQBdD3BLJ6bn51B6ZQzOakn0azu+dLBmiY+j9MIwHozcwlNNE+h4Mongpt73MgyYgm5U11D8zwlcMOsOOjrtPDT6Y24NLWOzG27+8C6y/uljdaiF307WQYPM6rUBz6TnZOKZ1cIf0xeRagnis+5gfl9yMVGODv6c+i7F7dFEb5U8Hjqby+bsQjj6Vr6GhlSxtyG+V98r8rPovq2JJEszWqkDs7OzT1lOlyU5idJvp3LbvI+Y5mhiSXs62xcXkPz+Fgy32/8Najp6fjZF90iem/Q8jUYIV264m5CPQggt9VA9yc73rl/C7WGH+bTLjbU1MGcMXdOHkHHNAf6U/ibRmg1d2Cn2erlyw92kPGHBduAQrelZADg1D9IS2DMX4XTiifWRa60FLGSENlKUHUvUwRiMurqAtg2QtKSMlyov5ZkwDd0DrjI3WbXtx543nUH88aJvMemOP5JttVBjuPnpvvlE7SrHF/B0oAmJtJ6dcndoXgx3X/s+j689n5hVcXCg+Nhz3qwEzr1qM1bh442XzyXl4119OggaMAVd+nwkvVGMZ1sCeqeH395yGUkXv8ATh2eR8hHoK7bitFjJ3R6PdDoCduR3lJ6dwd4fRfLkyBdJ0G283RHBDz+cT9w6QUm+YEJYLikfS8LXFyFkFtGX61w+bAf7h+Zh7D7zo2O9IJeRQUtYJEb1Kq8vzM6lKduoNkKJ3ezvjqeT6xieSPR5ldwVvotKn+SRvbNJfe0wvgCcLQF4zxtF+T3dvDB6AWXeKP7fO9eS9XoHeuFuiI/Bc3EM050HaTclbzVNJfWjtoCMwVZOt/CDhM+J0+0c9PpY0jqKp9fMIGuhD33DboiPpTuy/0Z/zeYWXHutfDRpGEMjC3ko8UNuviqerrp0bB8GvqD7Sstw1dTh0nWQEunxYPi+KNWWtBQMhwunMAALjYaV2kNRhNUErhvqKEOapIQ305GcjC1wvW8n5Yk0meI8wN/DpiODHcce10NDqS0I4p6YFZT5wnFWSYzW1j61NWAKOoCvqhq9rh5pGLjOmcy+7kSGhNWwJjyVICmRXg++ksMBz2FJTqL0qgR+MPk9CmwNbHCH8vCeOaR+ZOJcV0TEtmgwTMziwxheD476VJzCxvWRa7nxuvGk/+zM26ycFU2BrQFNnHkREFYbXdE2JgYX0WCE4NrX4vexhBPRHA7qRlt5NnsRppQ83zQFxzth+Mr2BKS9tmsnod1ay+tDXub1lnG8tuQccl5vwtxzAMM0aL+ogCtnrifbamFJRzQrF48hZcfmgGRJXO3jgbjrwSsILrYSWmIyZHcz8sAhpNuNDHHii+yPY88e0ush+e0qXpw2gR9MLCTfpjEpsYSdYSOx9VOGk3V5WtJTqbgsmZxph4jRe0pOoSeejEW+nv6YQDEMDI9Gl/SQ7apjTXx6v70XR7kvGU/28HI6TTvuymC0+rKev01Nxzc0g/YL2nEKgwXV04jaUNfnA9UBVdCh50gdIGF1G3+bOI3fjHmLJRPHEPNZGr5DpQFvX1gsHL4+jXOu3sJ5wYVcs+sWWtfEErHPIHhPNb6GRmg48aBTou4mZFRDr9ptGebFJTRqa8OI9LWc0fdquRlUXGJQYGvg9zWj0BqaA17Q9fAwGi4vYPicQsba4c2OBBYtn0TeR6UBOYXuuGoikfeU8mjGG6zpyuCfb8wgc2E1RlHPPmHJSKN2rOA7UatY2x3Kj1ZcQ8HCCnyB6PYBgj7dTV51BlqXF2rqMVtaMY87IvVGOolL7t8BOOPgITqaxtEzt0VD78XBgT/puVlUnR9H+7ROrhiylusi1mMVOi2mh7frR2HbuD+g+6nZ2Ymtwsaabhchuhuj95NHekWPiKD0UsHf0z7ifw9dSvKnJkZNz9mSNiyHfTc4eHT0yzzbNJmqP2bj3L+hz20OuIJ+zNa9xL0+lhcTJnP1pI0svn8iUdsTidzdFtBZC1pWOllzivhZ3FLm7bkJy4IoMlYXITu7MD2eU36vTQjCg3rX1WAN9aAJgbPQDqdRhITFgp6cSMvYBCpnwu+mL6TSF8SHK8aQ0xSgWQPHMXNSabyoi1eS32a/V+cXuy4lc1EXvopKv7elOZ00zu9gwZFi/tvXryLztRqMg4fQw0JpmZ1P5YU+bhr3GQ2mne/tvJbsF30BPQAwOzth8+5jR1TaiCF0ZIdhHhl3a8rTuSJhM3WGm/dqhmM/VN8vfcXHM2Q/zjiKiqRrXCaNBTa8PUui0J3t5ubRK7ghfAMJug0Tk6Vd4Xx/0zUEfxZCXFffC9ipSJ8PW4ugzBsV0HZOxJKUSMlN6dw5bRnbu1Op+yCZ5FWFGF4Plsx0Ds6L4NfnL8SldbFw6VSy3lznn3b9spUAkD4frqV7KU4fRvL8Zn415zVWT8/lvS0jyHaMwrK9CLOtze/tllwTyxPJb7LHG0bX4jjiPt6N7zT6tY7O+O1Nl8nxrG0gjS9OvCwJ8eCw40mOpCvOhs8u6EjQ6EowMcJ8RMY1cWnCIc4LquSNtlxSP/EGZLbP8SyZ6Ry8PITvjXwfj9T47v75hC10oW3eGpD+auEK4ea89STrVh5ecQV5b7biiw6hccYkWrJh6KRinkl7k0yrlUcahmP5MBx93eaAX78kLBb0uFhaJqVQcbHB6NxiHHpP2Z7mbGJO2DZebhlN1aJ0YksDP4gPgAQT+bWpgoFkSYin9OZMws6t5taULaRYe85gC2zVZFvtmPQcGpd6TX5eeDnpjwsse3d/qY890Fx6N4atHz7ghECMHcq++SE8cNF73BC6l0fqJ/V8yMXHoHV10zQ+nonn76bAXsUtO24m+7UOv+2rA7agAxitraS8VclKbSzll4Xzs9R3uHzWFu4JvoHERQWELN3j16Ku5+cwcc5ORtpamb//OqJ2dZ7RIIVHSiqawkih7IzbNgwNU0p85zdT7hyJfuQgvS3TxAw2CI9tIyW8CrfPQqLVjUUz2VMbT/OBSN6pDuOB2Z9S5Q0naGdgZw1oLhel1yRy89xl3BRWyJL2VGrWJJL+3nbMAHVviOOmcTpjOjhwo4ug9DbmZa1kWsg+4vV2YnRJt/TxQWUB8Z/WYXhPfTbVx0BYEhOouSSNxuEmw0aW8v+SPsUqfFiFwTibB6vQaTK7+Xt7AmHFXhAayEAP5Z8dZlwkybNLeSb7NeL0L9ZA0XAc+wrAJkxMCZa6VozmM+tW7KtxzmKeTQx8F5QYVcC+exy8NPOvTLJDhWEyK3Q37rkWFieOw1kahRzbym2xq/lb3bkEPx+O3Oi/iyEHdEEH8BWXkPJcK3WlOcy79Dt8b9xyXp/6d+4MvRGfYyihr/rnVAWgeUQUt0d+hFdKDq9LJrvim4ujHhND9XA77dLNq60jCfrY1au2w1Y7eCjnAm7PXcPB5Di8suePYILrEIVdCexsTmRfdSzemiCclTquUpPkgx1oTTUcvioBZkNRRwy+qsDOQ3ZPzGXInP38MGoPYOPDhuFE7TJ6dSHU6TLb2vnb5zMZd0ExWyY9T814N8s7M3mrZjSvFI4jI6aBn6S/hyk1qvfGErLPf/vE12g6elYah66L5/p5y4mwdPBB7TDu2zAfUR5EUG4zr45aQLZVYBcac6O28Z9X55Jfmo2x9yCYgS/qR/vQ4+2tbAoX9G6PPIP2mto4sC6VB61X4DEtNHQ5MUwNceRsNSmkhZvi13CxE65J38oHeediP3gowKl62Fokh9wxfCukGG98AD/k6Tkg3Ht3MC/N/Bs51i4eqDyPTw9nMyttPw/EfMrNF62hzggmz9pCsNB4VQoMm0APD/PbB9yAL+gARkMjrre2ErYrjSfuvIh7rj3AopHPcr31Ziwr4v1WxEwrBGtuSn1BxGwxMSq/vg7G8fS4WOrmZDH82j2s7w7lb0svIPel7b062Y3521p2tU5ide5ITP2LI4kVjCLsIIQf7CJrXxlG/ReDrhLwTR6JPrkJj9RYX5JOJtt60frp0SMiKJ5t4ztxG/FKg4M+k3Xbchmysjig00jNjg7yH2/iTvedBKe20tHmwLHPQcJaN5m1Hey/LQU93WRZ+1DC9wbwtFoI5MRhHLjCyR+/9Tzxlhaue+8+Ut8zydtVhTc1moN3OumWOns9Jp935TLKUcoL5z7DLR13k7xsLK6tVeD2IKXEqKkNQMYvvpzt2smLI6YRFxra5+lwp+IrLSP7sW5qN2Ria/YRVtMGxhd/BQ2ZGfzgpmQunPE0huzff2PsKvOxsSENLXoDmtVEczoDdo1GydUx/OG8l/igdSR3F4/A9YaL1N0trJg1nuZ5Qfwy6X3yrR4gCBOT78UuZ97VWUSsDIJ/p4KuORxoifF4I4PRfD17bKSuMz7mMPsTc8HPR6WrOnMJqvUgT3LaLux2tLRkqs+LJfG6EqaFH+DuT28h5/WuPu0soa+sO+Wy+Scqmp5IG5MS97OxO5WQz529bvt0NF6Sx9ip+5jkqKDGgB8WXUfCCvrlwhVj7wFyHjjw9SdGFRCU3sYkOzxWkUBYiTdgGcTYoRTdp/HKlD+zx53Ef26aR8ZiH/YdJXiGplJ0m+Dpac9T4o3mp9vmYt3kon2Ih2+PWc9vL1zIB+NH8PmKYVg6BJYOSHjU/wVdb7JQ6HWTbbUwzg5TRu+jalwOluWBmb55lFFXR9BbPfvBV/fToMZmrBPzYEZAI5yQtc1LU3cQVnSCnB60qMiAFfTunG5+sWcO+ofhpL5ZhFGzGxNI7s5mVe4QSuI+o9irsbhpLI2eYPY1xmJfHoqvyn+TPAZ0QRd2O3piPK2j4qmerJE6poKfJa9BQ6PGMFl+OJekLf6f87yyPhe9y3vCgQo9IoKuCVkcvtDCFTPWE2Jx88SLc8n9Te/XcPGHInccMdsCe3WouKGO/0t9B6ew8UjDKOreSCH2rcAPPp4yk9uLxxOEiaSwLo7UzYE5W9CzM9j3gJU3pz7J8o4h/P2fl5C2tBO9q5v6Obm4r2zmp3mfsqRpDB8sG0fOCw2Y+/eiJ8Tz6aQpvDxzMrdP+4z7rn2cDmnjocKr4VH/54zcKXhyxrn8MXE1ANPCD/CXcQUkLvd/WwiBHhuD2dyCPMn4iR4eRtv0bFwTAv+hfyKW5m6aWoJpl15iXO14k6MQZeUBaSv2IxuRW9sxD2z+YgxH03Enh5GUXk+6pZ1Lt9xJzJ+d2KvbiO32YFZv8+vw9YAs6MJiQY+OonNkCocvsnD1uev4btRqEvQg3NLLDo/GCw3n4t0T6tcLE6QQaJg8nLaEewseIKo0BtnRgbDbIToCMzyYqvEuYq86zKLMRbzfNoKXF846tpLe2WQVBoZdD9gv1JKRRlZYA2GaAxOTl/eMJ3ND60nPYvqLPFyJt3FowNs5eEc8707/Iy7N5PFVs0koNKkd68SY0cLDw14m3VrPrdtvJvTFUHJW7j/WNeYrKyekrJz8T8JYcuVMnp0+DTwa+Y82BOSDJ6ykm7XVaXQnrMApbMRY2nBHSITdftKi2xt6eBhmRjJl54eR8l495v7iY9eQAD1jDaEhtJ4/BO6o4/2hLwI2vFKnHyfgYO4qxLFtCqvGJTAmsoxVeYlEBGjCUdjL6772O7WkJXNolo0HUjfyTns+rIrAsnxNwLooB1ZB13S0IAfm0EwOXehi4pydLEj4gGRLEG5pYa/Xy5stY3h+7TSyFvpIX+Hf34yQEhONPKtJwu3FFMXnEH7AoD1Jp3N6O3cM/ZwLgvfQbAbxi7JL2fNpDhnvNfXn/nlS0ZY2OhKtBGIVZ83hYO/343k+fgkAlT43HHKilewL+BIM38QYkU1EcuBnTNw+ZykpFo1uKXn43MXoMyVDbFUY9Mxznr/uTpKftWBdtgHjBAcZRnMLkc+tJfK5I/cDlFNbuZWuaVPYWhDMVIeXK4KbeXPGXhpTEjH8OBDZcHkBMbeV8EHm37m87YfEe32I7i8+3M2oUGrHheGcV80bBS9hFRq7PJLP6rKxNffvQUBIuck/68axoSid3Jf774xSWCxUXJbELZcuY7ijjDsW3kP2gr0B/ZsZGAVdCCzxcfhSYmgoCCH65lLey3zyWCE/6HWzqHUMC1bNIGuhh9zVGwNyybDugWbDiUYbr2W/y8F7fRzwxlBgqyFZt9JievhHy2ie2jaNmA/tpL28ZkAUc+g5QvfZAzMgKIfnMGHsAQqsHbSYMH/3LSSu9mG2BG6g7XR5Q61EOAN/Reaiw6MYGXSYFEszoxzlVPrCeKjoaso2JZH4mY/sjSUY9fWBvZT9NDmrJR+3DmOyYzOg4QvAQGTePbt5NPkDXJqdqHnl7J8ejWl8sf8NS6vk8ZSXGGc3aDHh1dZsfvfZHNLfNLGsDcDyl6dB0yXCaum/s8qReVhn13Ohayf37Pk2SZ/5Troeu7+c1YIurDa0MBcyMYai/2fl/mErmOcqPLJ8bhBNZjdPNY3l+Y/PJXNRF7mbtgb0lxG+voJf7JxD/OhXGGfvJNdqI9faQpMJn3W7+OXBORgvxJLtx6mS/pJuq6MlFwJxTZzXZWOYq5IwzcFat47vzRjs7689q33nRzn31bK3Mhry6ZkmpwVmidTo+TX8z9zbaBwOejekvd+BbfchMtrLQMqzfqZyvJhNzby2eyw/idmAXQRmVklVZxg1hoZTSN4dshiGfPGcISVeDNzSZG23iz+VX0rJoizy/r7Zr90+p8u0CGLtbQxLrqRtUn7AB4iPOvCgjbeHPcPvqi7E9lwktg8D8893jveNBV0IkQL8A4ijZ6bcU1LKx4UQPwfuBI6OdvzkyH8wOm3uWSNpv6+FH+Z+wCXOGjQ0OiU0md2U+azcseN2Qp8OJfuTrXR1N7GbjXjoBgRJZJAqciiSu6nkENYjV6NlM4xo0bv/POIrLSPjAYP7v/0dbrjxEy527QTgnsIb8b0SR/THxbRXLWdzgHOcjm7ZyW420r3iM3bs9mC7wQouApJDmJJu03rk6sMvF8yjOc7W++ErOUxQYTJvZkDlzxdQ2uYG6fZ7DqO1lfAX1xJ+3GMnOjs72+8HgKioRV8by9jH2zEa26nxLiK1fQTJRPkth/bTCC69+QGemf0sE+0dWIVOt/TRaRos70pjY3sGK8uz6V4iqH/5edzdzRSfpfejJRsucq/k2nutiH1tIH39kiNihYO/DJnJqu1DGFLYPwvmnc4Rug/4DynlFiGEC9gshPjkyHOPSSn/0NvGy8+zsHDoS8TpHppNeKNtGH/efB6iwUb6u17iVu/qWbkOEAhyGEGoiMAnvWxgGZGy599JpJJDmsjrbYwv8VVUkvj7Spb/PpjlTAIghGKgGF8/5vgmR3NEpE9i9512Fj/2K2xzq9EDkMO+r5JXto9n2tT9dJh2xHGHowPh/Uhc1cXPs+fy8MNv88e6+8l+tJ51e548q7+Xs/l+GPUNJP5fOW7GEioiSDuSI5wp/suxbgd5W+08dPNdnH/PWm6JWMPDFZeyeVUeqZ94sG88QGxrIW7ZRTi5Z/X9CCmFRyovIXROMKOaJd3lpf2SI+rZtRQ9C7ls6Leu2W8s6FLKKqDqyNdtQoi9QJI/Gs98aC0/eWjClx7LYcsXbR/3uF0EYafnsmKLsOKULtx0+SPGGRloOYzd+xjyIGyTkSQ8vo7mALTlq6om5+ZqHiMfgEi+GIweCO+HZeNe7MPH0PqdfP5Q8Bo/av42wT+KwG2o/SOQOaTbTfRTa9n2FDzIFKCRzCP7xtHP/IHwfkQ9uxaehWE04zuLOfrDGfWhCyHSgdHAemAqcJ8Q4iZgEz1H8V/r8RdC3AXcBeDAPxe+dMkO2mgmjEiaqaeMIqrkYVxEkMsIrOLrqx6rHIM3h9ndTfyCLbxfcy7rvldKfsYmlmsthBn/nu+HyvGvkSMQhDzNUXkhRAiwEviVlHKxECIOqKfnQPp/gQQp5W2n2kaoiJQTxaw+BfZJH5tZQQb5xIok3LIb25H+ryJ246aboWIcAOvlMlpl49emfqgcKsdRS+Ubm6WU447fhsqhcgQ6x5k6UY4TOa2CLoSwAu8CH0kpv3Z925Ej93ellMO+YTttQF/+e7EAsoFW4EQLrdiAnCPP1QNpUsqYE+SoAzqOvEbl+PfNwYmyqBwqR4BznK7oU+U4ISnlKW/0vAn/AP70lccTjvv6+8DC09jWpm96jT9ynE47vc2icqgcKofK0ZdadgaZz7iN0+lDnwrcCOwUQhxdyu8nwHwhxCh6ulxKgLtPY1t9cSY53lE5VA6VQ+UYgDkC6nRmuazmS4tyHnNGc8776kxyHP8PEVQOlUPlUDkGSo5A69/FieGpAdROf2RROc68DZXjzF/TVyrHmbcxUHJ8yWnPclEURVEGtv4+QlcURVECRBV0RVGUQaLfCroQ4iIhxD4hxEEhxI/9tM0UIcSnQog9QojdQogHjjz+cyFEhRBi25HbJSqHyqFyqBx9zTJQcpxUoOdSHumj14EiIJOeyfvbgQI/bDcBGHPkaxewHygAfg78p8qhcqgcKoe/sgyUHKe69dcR+gTgoJSyWErpoWfy/ovgJHYAACAASURBVNy+blRKWSWl3HLk6zbgmxYOUzlUDpVD5ehtloGS46T6q6AnAWXH3S/HTys2HiW+vHAY9CwctkMIsUAIEaFyqBwqh8rRxywDJcdJDYpBUdGzcNgi4EEpZSvwJJAFjKJn6d8/qhwqh8qhcgz0LH3N0V8FvQJIOe5+8pHH+kz0LBy2CHhZSrkYQEpZI6U0pJQm8DQ9p0oqh8qhcqgcfckyUHKcnD869L/pRs8SA8VABl8MJgz1w3bPaOEwlUPlUDlUjt5mGSg5Trkdf4Q5zcCX0DNyWwT81E/bnEbPojo7gG1HbpcALwI7jzz+9lfeFJVD5VA5VI5eZRkoOU52U5f+K4qiDBKDYlBUURRFUQVdURRl0FAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkFAFXVEUZZBQBV1RFGWQUAVdURRlkOhTQRdCXCSE2CeEOCiE+LG/QqkcgyPHQMqicqgc/wo5+kxK2asboANFQCZgA7YDBb3dnsoxuHIMpCwqh8rxr5DDHzdx5Ac6Y0KIycDPpZQXHrn/X0c+IH5zsu+xCbt0ENyr9k7GwIebLpy4AHDTBYCdILrpwCPdQuXo/xynyiIxB0QOO0G00VQvpYxROVSOs53jVE6U40QsfWgjCSg77n45MPGrLxJC3AXcBeDAyUQxqw9Nfl2NLKeBagrEOACqZCktNDJEjGa9XKZynKUcp8rSQuOAyDFEjGapfKNU5VA5BkKOUzma45sEfFBUSvmUlHKclHKcFXugm1M5zkIOPTqKyh9O4aZ9ZdS9nXfWcvSFyqFy/Cvk+CZ9KegVQMpx95OPPNaveroSuo7d76YLO0H9HePfNkfnlRPpejWEF+99jCRLE81l4Wcty8moHCoHgB4VSdPNkwlbHUXc2lD0/JyzkiOQ+lLQNwI5QogMIYQNuA542z+xQM/OoOHOydS9nYd1RQL7/zaBwz+fQssNkxBW27HXhRJBF+10yQ5MaVJDGTEk+CvGaft3y6FHRFD+X1O47lfv81b+QjQhuXvTDeT/przfs3wTlUPlsGSksf/HefzPz54j3tHK+uVDoa6x33MEWq/70KWUPiHEfcBH9IwSL5BS7vZHqI6rJxJ5fykL0h4jzSLREXRmGXik5I6D12IW5SPWbgdAExp5chRbWYVEkkg6ISLMHzHOSF9z6KGh1MwfijChOU9ihBrcO2U5n9blsa88DtOtH3ut6NQJ36MRv7wWY3+RX3OcDktKModuTuX6a5Zzc+gBfls/gUWLp5O0zoOvovKbs/RuHP5rqh+cwpjrdrJ65TByHtmPUd9wwtcNln3kVNwXj6d8lk7yiGquSNrGcEcZmzozefa988n61S7MtrZ+yfGNNB05eTixj5Tgkxr5V1/E1sqPAppDGzGEPd8L4Vuj1/PD528j46VyMht2YbS39zw/QPYPf+jLoChSyveB9/2U5ZiwtWWU3xRGom4QpvWMJoccee6p7Ne4/n9uIuhXo9FWbQUgWiQQPQA+UfuS4+BPhvLUvL8TrnXh0rxYBcTpdu4I20lHlol53GsNCS2XWVl1fy5P7p1O0Mcu4j8qx1da1uccp8MMC0Eb08J3I7ZgF3aKO6KJ2e7DtnLn0WlgxwQqi+Zw0Frg5aH4jygcEYtneBr6pycu6IHMcab8nUOPiqTo+3ncNncpk4MP8HHrcFY3ZqNHSm4N38boq0u4O/RWcu/dENAcJ80XGgpJcRguB8JrIq0aJXOCWJD8Lj+rvJgYTxSR4qKAtW9JiGfv7eHcO+kTnnpvNjl/2Yuvqelrrxso+0df9amgB4qvsgrt7TR+kzSdX8evp8Zw45WQZQ0h1RLCrWlreHzCt0hYdbaT9hB2O1pqEr5oFyWXObnkwo34TJ33140i5/71p7WNubPXMdnhxoIVsFLi6+SRhuHUe0OOvWZvczxBFi+jw8uY6drDXeEHmTthNw/GXknLwVQspWUnb8BPLCnJ7L0njKdHPkOIZufbh2ZT8eccQpfuxHS7A97+UabbjaXRQqXhIimkhZqIaJz91vrJySkjqZoajCdUYh3ayn1DVtDoC2HBrslkXb/N7+0V/iKH75/7Pm9Xj2Dh4guIW9OC1t7F23EzefTG2ay5+DFumvo57996DpHPrfV7+19lyUyn/PJE2ka5sTk9xIa1MzN+D0ODynm3YSSfry8gf1QJOlDYFEuEpe0bt9lbwmqjbH4mE8YV8uTy88n/W+UJi3l/0IKD8UwaQvHVOtdM2kCGvY53a0dQ+1w6ES/47/cyIAs6UhL75j4WTxjLbbM/p0PaMaVGlrXn6c3t6SSsCtyOcLr0uFiaZ2ZSda7J1RM2kuWopcBRwRhbN15pYp/iZddpbmvNbyYwJmcywZUSYYK10yS4vAut2/dFex4fbk3jc1c8L8yfzodzHyXL4uSquC38emIOycsD83Mer2FGMheM306JJ4Y735tL9mtuQnfsxuzoCHzjx5OS+PUmT0+fwRBXDYeic85aQdcLcmkeEUnTEI3EaeX8Nv01goWHREsbGRYHXmkwY9Jebn7lNr8WdTl1FJdP2kxRdwytLyST8M5ejOZmDCnRD1lIjhnLA0Pn8nDyO7w6exyRz/mt6ZNqHRVHyhWH+F36YqzCREeyojOb1a253B23grsvX0Gi3kmxz0nHJ3GENZzWbLzeZfnWGNLnFrOhKJ28Z1rwlRwOWFunoudmcej6OM65ZCu/j1lJntXELqzMDdnHEw9O4e34aST9bo1f2hqYBR0wGhpJWJbL3anf5ne5bzDS5qGnqx7afTb0li6Ms5TNnD6aonk2YrMbuCX9HcYElVBgNTjoFdxTeD01B6JJWgH2Ji86W05rm6Hv7yLcFYLZ0QmmCYaB6XZjnuDCL31UAVqURqKuYyJZ35ZJzDavn3/Kryv7f1M4d+4WLgrfwQOffpu8F9ph+z5Mn++bvzkAQrfXsKsmgV+NfZtXRk4hLjwMo7kl4O3qMTEUPZCNc3gTTruHNFcdM8M2U+CowJAaDuFlssMN2DAx0YUgz9rF7JxCir5x66fPE26lttvF2h05DNnShHHc0af0+XDtrGXT1mxi0iSJUS1owcEB/eBtv2YS1juq+V36YpZ3DOG1srFU74wjaaWB5pO8c/lols95lBjdwvPNw0l5swJfgPYdYbFQPVVybmglh3ZlIvfsgF5eRNkXemgoxd+O466rPuTikF282z6ca3dMx+iwcvvEVdwSuZZ3Jg1DWCxIP7wXA7agA4QvO0B3Qzo333o7S6b+laFHJrecH7GHR+YOI/H3B/s1j+Zw0DVzOFW3uHli7At4pYWlzUP5wweXEVSlYW+RRG1vJ6KxFqP4MJin/5FjdnR88x+bptN1+Vhq5nfz6JjXCBI2flY7inX/N47otXsC+gEnJ4+k4ML9/Dx+GT+rOp+ILRa0w7UYZ6mYA9DZhdcbSrrFSWpODd6RmWgrtwa2zQnD2fsdOw9P+SfTg0pwCHAIDbuwcMmea2hdnIDmg65YgXtYJ4un/I08q06nlGxvSCSEYr9FCd5RReWvsxlS0Q7FJzj6bOvA2qwRpjmYGbefZedPI2jJhq+/zk/akjXuTNqKVZg8uupCMl83yDtUiWxto+2cHGLSGgnXNFZ2h/PqB+eQURq4LF0Xj2HYyFLe2DeK9FUdfimWvVF+5zCunruKaEsrc979PmnvmuRUtiFtPl5omslV12xhStIhyrLSMfb1vZ4N6IJupsTTmmYjOqKOON38ypP9n8czZSiVN7uZP2Qz31s7n4gVDkKqfOQVViObWpAeD2ZHR0AKq56XTe20GCxX1fFa/svk2zT+2pzNW4umkf7egYAemWrBwVSND+ZbUXuJ0BzsbkwgtMyHeVyblsx06s5JwBMqcDSYhL28LmB5vkoXGvHBrVRExgW826VoXgiPTX+R84PqsQo73dLHg+WzWbE1n6SlgvhPdiOlxDM+l4pRBjGaj07T5LmmCYinY8CPBd1XUYWjqvqkZ0iypRVntWCHx2BYUDn/HGIhaYnfmv+ayH1e3q0ezoysfcSnNeBzRiGbmmmfkUfLza38ecgiPupM4iefXMOQF+oxzuCA50xVT9DJtHdg3xSCvmP72SgXAHQkm8x07eGJ8vNJWga2Dzdi0jPt11mVT6e0YErNb2cPA7KgW+LjKJ+fhW1WPTMT13FV+Cai9S/WTtjSkU78xq5TbMF/hNWGd/pwKqfbMYIk8rCN1wtnkP1+G2LLRqTPR6A/+y3pqez9bhTXTf+cb0esZ4jVjg+DZfVDiN3s/VJhDQRhtdCaZ1DgqEBDUFkdQV55O6bX09N/PDyS5hyNURfvZXTYYSrcESyZOoH8/y466VRCf5ESDGmiIZEBvu5ZjB3KzHN2MMVRg1XYKPZ6uX77bdjeiCB/Qx1U1WK0tgJgODSmph4iUrez12Py/JbJDHnPz4XFNJCn2KDZ3Y292aTEG41D82AE+FqZ4C1lFG5Ppzg1mv/K/oDvn3cTITlDib20jOcyF1HhC+enH1xL3oJmjL0HApZDz84geGQjK/flkLO6/diZrx4Tg0yMRqttwldVHbD2jydMMKRGcVMkcY0e9OgoPMPTqBzvwDe+jafqZrDhlZEkVmz3S3sDsqB7sxKInlPOq3mvEqsHc7Tv/KhYaxvrk+yE9kMWz4zhlN1mcF72VlZ+OIr0N1vRG1vxlVUiA3iEcbzGKYlcN30N/xu7DY5cdqyhcV38Bv77pnhsI8YRvctL8PZKfOX+v1jXzE5h2LBShlg7OOyTWKpsaPVViKhI6iZF4ZvbxA0ZW5kfthldQKNh5bqL1nNrzf1k/PUARl2d3zOdDcVXh/KTmM8J02ys7HLy4LZriX7RSfDyXRhH5nkLqw09JZGy0VZ+ELWFOsPNk3UXEPW5DbO7u38DC4HUBFbhw5AaIsDDLL6aOpyVmZR5opgfuoe7LlhGt2nlnsiNlPhs/GjbVWS+6cbcURjQHHXT4ymI3sv21QVou3cicjKpuiCelkndhId30FKcTtY/4xGf+3/W0VcZ4T6SLK1MTizhk3kjkNdlkZlTTbyQlG5IZvtbI0n6+ACGn8Y2BmRBt9S1cbAwgVWpCVwR3IwuvnzoNcZZwvMjBKGvBD5LyeUWXpz0NP9bchmxmw3k9kJ8/VTIjxIGbGxMY3P4ZgqsBkHChoZgXkgDM6b+hfdHZfPPqrHs3ZtMyodJOFfs/dKFJH1q226nKd/FTTEr8UjJY3UzCd8HmCZt5+TQMruDx4a+hUvr5qfll7G2MIvgiC6Wj3+Koefvp/PVMAhgQReCr+0fASNhZ3cK1b5WfrT0WjLeMnFs2HesmANoOekUXx3NBZdvZLitlsfqzmH9S6NJXFnd74P4WkgIXTGCobZaPuzIJ+zQkcN5IdDDw5Gp8XSmugjZUv6lC8J6zTSwt0hqvKGEaQ5+EFmIhmC/V/Cf+68hYlEw1q2BHesBqJ/uxVcXT9QuL7Kri7pz4vDMakF02miqdxGXW8+BW8PJr8/2S7/1qWg2Aw3JPTEruPKiLaRZmkixaFxfdAXp73Qi1mz36/sxIAu6sb+I3BecPOS5nieGVeO0egCYEX2A+yN249TAcPTPiLUlpptMSydJzha2JqTiio3GV13TL20fFbGugnp7MtePvB+R0E2oq5O8yDpuilvDBUFwS2glt4RWUpLVyV1511ObOIzov/tnbqvIy6DuAjfjg4p5omEaS98aT9qmRtrHpVI9z80jYxejI/nOlhsIeddFYodJ3VU6dYbGgYYYkprq/ZJjIMh8s50nWy5D6jDk3UbknoNfGhS2xMdx+JJobrx6Gf8RtYuPOmNZ8ukEcp/fdawrpl8IgeZ0QmYy7ekG6RYnMZZWmoYI5Lcn0RWr0R0lMTO7SIiqo+LddOKe8ENBB3wOgUvvRqNndeT93m7uKLwB+Xws4UsPBPx90KOjGJtTwubdmSSUNENUJB1JAu8hF3nPNiDau6i4MpXhVxVzaG5mwCdWRC11cInne8TEt3BbxhpmBXWy1WOy80Ay+UWH/f7hNiALOoDcuJO85kw8SZF02zSkgOcnpxN9bRtjHaXICA+ay+W3I9HjWeLjMFvbMDs7ca1wMj/qBu5N/5S2G+wUe3OJeb0zIO2ejK+0jPB/lBEVHoaICMcID+FwZi73zsjl+nPW8O3w9eRaHaRbnLyRt5Cf3nEeB3eMPLY8Ql80jorg1xMXMtIG1y+fRN4rlXTmxlBzYxdPj32ZQncCv/tsDklLBdZ2H2U3efnD2MX8V+mV2N8Mx6jb64d34OSO9qE3e4KwtQX22E9u3EnSxp6vT9R13TArgwlX7+DByJ2sd9v4j43XkPGOO3BFTNPRQ4IhNgpvQjgdiXa8ToG0QHeUoCPdx3mjelbjOC+okrZ5b/JJYwFjw0pZ25hJbaeLmmYXDv0b2jlNxrlj8Mxo5fyQ3RwtLVvcKTStjidl4Zp+OUMxMxKJd+xH69QQXW6w2YgsNLE3+4712ycudbIrN43E86rh94HNE/HCWmKWJdE1JJ6/fHcGt094kX/UTyN+mQWjptbv7Q3Ygg5gHChGP3CkB10IIsInsr87nguDD5IQ14wWHenXwqo5nXRcMIz6ERbiNngIWruf2Be301kxjH/85xQWZr/J2NlJxK6KhX4s6EcZzS1wZAA0eCvkb07lw53TWHLJcBaOfpYhVjuhmoP7Y5Yz9/LRZPjhIL09WRCpt7PJrZOwWiIbmyi5PJZXxz1Pq+ng959cRv7fGvDGhnD4XoOPJv2V+4uvoWFBGhEvBv7KxKPKmsNJKWs5a9cm6NkZ1M/p5qmUzzDRea52Osn/sKKt3Oj/xjQdxhXQkhNMe7JGZ4pBeGozl6X1XIFoSI3hjjLG2noqdZXRyautI3mnYgRllZGsd2cTs1YnanMTYc0N+Mp39C2O0wk5aRz6jo/Xxz5LpO7lky4XiZYWHMKL7Mcq43XZCNI9OOo0ZHMrZnsHYR+29sxAO/IaWVZF+K4opk4tJvC96OArr8Ae6cLns6IhWF+TRuy6qoBMphjQBf14lqREaibD7+K2sdlto7IykrB2/15l1njVSMZ/bwtBuoeP2yeTvMOJUVVN8KEWKltDaTR9eN2Ws3KBwon4Sg4T9fRhvKXj+MuvZvJEYs/VZjZh4nP6J6MvSGITBgtqz8He5IWkeIJiO4nTu/hz1fkEl2nUT4ymbpLB7flruXzT3US+HEL44v4r5gBdXTZoPEvdO0JQOzOeq/J7fubdHh8rC3PJ31kRkD9a7/mjKb/NwwMj3mOovYJW08HWznTqPC52tyZwuDWCcbFlpMcvI0RYebppIkuenUHihzXk7t98bDsm/pn9K/My2H9HCH8bt4BqI5T79s2hoiyKi0ftZHb4LuTX/jdV4Fk7wOzsRHo9GF7P154XEtymBQI+R62HLyKISFcLDWYXrR0OYmVgBsgHREEXVhuMyEFr6cQsq0R+ZU0QYbFQf14qV0zvWRflo7bhxH9i8fvsiajbSvluzKdct+12rK2StompaO4UKmZYuCNjKX+onUn4WjuyzD/9jd9E2O3oSQkgJWZNHWZn5wlfp3f6ONAaA4k995tNG6FF/hkotDcLOqSNDGc9+yOHInxBOGxd6AJmRe4l58Za5oRuY01nDv/3wUXk/eEQZuuhfp/3KwCh9dPg6JcaFlgSE2jOk8x07aXC6OS7+24i7VWBr7IqIE3aflzFu1mv83rLWG7fcjOWUgdROyTBlW6sjZ1Ee30svXU0t1y3ikpfBC8tn07uU1swAjDLRo+KpOSSMB6d/Q/azCB++NF8sl5zE5tpoXWog11dyQT5v2fhlDRx6oMZkZJA01CTTXWpBPvxuoCT5nE46Iqw4rD4eKFlBPrOEGRHYPaNAVHQzXH5dPxPG1X7Y8l9zom2vwSzqxvNZkWEBGNmJFJ7rpf/jvucesPkvcqhRK4u9/tna82raSz4zlT+PuIlssd24xA6WzwOdExWd+TxybvjyXy/DF8/TD8TVhveqcPYf4UFV5FO8hKJ+dW1KIRAj4ygMTeI2xN6lhgwkex2JxK7yT/ToOI2dFF8Wxw/jNrJsxdPx9IYxBXJ23EJjRtCy4Ay9nkNntk3lazXO/p9wPgoR5AHGe6CfppfDPS8/7lZlM2JZe7MdaRYmrm3eB7uRXGErt5xwmUb/OH+1GUUemJ493fnkvv27i91O4q0FA5fm8IlszfQaITw/c+uI//JuoAUc4DWc3O4Y/6HDLdVc+lzD5H/j0pkkJ3amToLEj/gTzXn42jqv493vdtHszcIb3BPV5DxlYND/chU27icWlo/jg98Qdd0vJMKKLvM5OrIMv668VzyPmoL2FTeAVHQD8538HzuC3Rm27nPfRvR24YTdqCDzrggGvMtWKc18Oqw53EKGw/Xj6J7cRxG7emtkXImop9ay6fmZBaNmEDBiMOkBjehIdlQm4qxJJrMt4vwBWAg44RG5eH6n3I+z1jEnF//ELP2y90JmssFmclUnhNB5rwDfCe8AkNCua+LPxReQMIaP12o0Obmo7oCpjv3s/PiJ7ALKyYmdYbJAQ+UeKP5++EZBL0bChv6t5tFGiaGT8ctfQyPreJwQS7BgR2D/RI9PJx9d0fz2GXPMyOogQu234Trj6FEfbouYMUcoNkIxpACa6dEJMRiiYqAbjcyMox9t0Xy35e+TpatlpvX3s6QP3d8bc18f6ofoTPOWcxLzROIX+tBNrVQPXsIk3MLMRDsaownqDbw6wwdZSmqYsWhHOTIdjqnZBO0Yg/S50MLciAiwqmZlYjlW3VUV0SQ/0JhwMdcLGnJlNzj440Jz3DXrhvIeLlncD1g7QVsy2cge2E3D2VfzS9yl7Bj/uPsvRpeb57AhOBiLnTWEqI5MKTgk64gFi6bSs4/tgZsqdaoZ9YSBXjh2EJKERwADvRTb1uPfbcF8Wbq28TqTlqzJVFjcrFWtyB8BtJmpXZ6LPE3lrA06xkitCAMCU1mF7+tuYC4xxx+y2Fu24P7l2O58rrvcvuE1eQ6ek4V/1oyk8pNCYTvh6hNTUTu6t9iDmA2NaGVZ7PDoxOkezGt/ddZKywWzOxkxk44wHlBjbzRnoZ7aQwRy/2zat6p/OnALP5UsJCIB0sxpeBATQzG4WDihtfwy4zX2NqZxq/+OY/cF6oxDh4KbJgj3Rtu00J31P9v79yDorrOAP77WNZFQHwtKBERVJRIo4akkWhb26QdjU2HTuu0UTOmrWOazGSMVmubtJkh03Qyk9Rg+0eS0UkbTTu1Ru0kMU7SYFqGFoOIMfioIo9oQPABPpA3y+kfd63YLsKyu9fN8v1m7szleDn3N4frN+eec+53omnJzWTuioM8PLaYJ09+H/PHRJwF9qWB8Jw9R+Kb6SStqqZypZsY90xiz3dzebKTKzltfOv2Ut4qzWZG3im6G5v6rzAAxOWi+pEJPDVrB3+48GWit4/FWRDa/yf9BnQRmQhsBcZh7TWzyRjzWxHJA1YC194dnvZueOE3UvwJV4rn8pPClSxdtpeHR5Wx1m19kecSKzgVnmrhO8uF6JPPcg5hAumkSgZV5ihnqOHaxq1T+QJuCV2i+nbTylFK6aQdQujh3u+g7KuTyBpWx4klL/NubjxFzdNp8bgYFd3K7KvbeXV9PfPPe0Agd8lw6hd9l8KHTtNQ82ZQ28NZUMa0AigihiLSAXDxKel8SrtppdSG9vCF6e4muk241BNLdvtB/lJcRJQ5Z4/H7EwqlsfyYlIp77cm8eKWxUzaepwWG56PMQ9W8Nj6J8hdWsS98SdxpBi4C16u+xq/en0Jk95uZPyRvey34e/SFW8YhofGrjgyVx3l8XEfkhbdSc7eVUzPb6Xn0IeU2fx8xO0o4XzPHMY8dpann9nBMPFQXRvF+lVX2VzThePyHqpD7RHloO0bs8hZeJg7XLU8W5RLZvmlkM8tDaSH3g2sNcYcFJERQJmIfOD9t3xjzG+CITLxuWLE5WLnxft4Y/z9tKd0sSKniO+NLOO8Zzg/KPkR2Z1niJMWuk0X+9nLGDMOgFQymCT+7TY/WAQhg5kkyOiQeiQWNfDr7FxGLfgz84fXMzemjfnDG3HioIcePvN08ctn4knPimZzXTYvfbOUu3bFElVzJiLboy/i6gwfXM5iquMEiQtymbb5dOg9ohycXBrPqw+8xhddl7l3349JLWzB09hkW3vc9kIxpS84KCWzV2kDKVhfpNrlkVAVxfHOZPJvKwSgostw/4GVpG6PwhyrumXPR+yuEtgFG8gCoMO0kUG75UHoPRzTJxO3tpankt9jwfuryfxdMz1HQpvyAAYQ0I0x9UC997xZRP4NTAiFjOnowL3p+iuJ1SOcB8DtXE/mEy1OYs0IV77LEgAABGNJREFUOrAnQVdvXDL8vzuCh9LDU1nDtHVnyP/HEn76FSGqU3CmXeWO5DNUXRzLxYvxOBpcJG41jDxyiZFNH9PRFNh64sFgV3v0xbjd1exJyaFz6ixS653A6ZB7yKxMSOogJqqLZZWLSdgTT3RVFR5ufXtcwy6P5G3HyXcupuaHhVzsimV3STYZW1phfynGRo/+sNPDkZBA5XI3z034G8/XL2Tiu2JLMAc/x9BFJA24EygB5gFPiMhy4ABWL/7/9ncSkUeBRwFigpTctM200MwlRjKGS1zgM6qoN6cZwWimMROnDPPl/rnzMB0dxO0sIWPn9bLLgJtG3L2uaxki7eGL7oazpObduLIm1B6nHxxJ/pzXae9xUrs7jZTdJ3xmlRwKz6mnsYnxG4v5aKMT6CKDvrdcHArtAdCwLIufffuvnOp0U7FhBvHvHAiK90AY8MJdEYkHdgKrjTFXgFeAKcBsrB78Bl+/Z4zZZIy52xhz97VxqkDoNt2Us4/pzCZanKQwhXk8wBy+josYKvDdS1UP9QiWx/h9HZS3pfL4OytIeaveZzAfSu2hHr2umzebOx85zPMfL2TPuvtIeO+YXxvdBMqAArqIOLGC+Z+MMbsAjDFnjTEeY0wPsBm4J3SaFj2mh3L2MZ5UksQa9XFJDCKCiDXhcoXQzlyrh3o4C8oomhnD1DUf+VxFMtTaQz2uI/86RG3OVaYsPWRtZmFzihAx/ayXFREBtgBNxpjVvcqTvePriMgaYI4x5qF+6moGTgTgmwZ4gN7b21vvehZJQDxwBbgATDLGJPrwOA+0eK9Rj6HrgS8X9VCPEHsMFPfNPHxijLnpAXwJa7liOXDIeywC3gAOe8vfBpIHUNeB/q4JhsdA7jNYF/VQD/VQj8F6+Ons9z0Gssrln4CvLzYGteZ8sPjjYb1UqId6qId6hJdHqLkF2YwURVGUUGB3QN8URvexw0U9/L+Hevh/TaCoh//3CBePG+h3UlRRFEX5fKBDLoqiKBGCBnRFUZQIwbaALiILReSEiFSKyM+DVOdEEfm7iBwTkaMi8qS3PE9E6kTkkPdYpB7qoR7qEahLuHj0SajXUnrH6B1Y6cUnA8OAT4AZQag3Gcj2no8AKoAZQB6wTj3UQz3UI1gu4eJxs8OuHvo9QKUxptoY0wlsA3IDrdQYU2+MOeg9bwb6ywSpHuqhHuoxWJdw8egTuwL6BG783LaWIKfglRszQYKVCbJcRH4vIqPVQz3UQz0CdAkXjz6JiElRGWQmSPVQD/VQj3ByCdTDroBeB0zs9XOKtyxgxL9MkOqhHuqhHoN1CRePvgnGgH5/B9ZGGtVAOtcnE7KCUK9g7Xe68X/Kk3udrwG2qYd6qId6BOISLh43rScYMgMUXoQ1c1sF/CJIdfqdCVI91EM91GOwLuHi0dehn/4riqJECBExKaooiqJoQFcURYkYNKAriqJECBrQFUVRIgQN6IqiKBGCBnRFUZQIQQO6oihKhPAf+uu/uHYAR7QAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape #1D tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doBX2JtUO2xP",
        "outputId": "a4a35eee-685f-43b2-8f2d-10dcc23b00a4"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[5]) #tensors are lying in the physical ram, memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "59b4I0YkPOhn",
        "outputId": "4ae838cd-7e4a-45b2-e629-c45fdb98fa21"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fddccacf090>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mlp is global in nature, cnn is localized , its approaches is local\n",
        "#mlp cant work with array(cant be greater than 2D, means 3D,4D), it should be converted to matrix(2D)\n",
        "\n",
        "x_train = x_train.reshape(-1,28*28) #from 3D to 2D,  bydefault dimension orientation"
      ],
      "metadata": {
        "id": "oLpnUvo1PReO"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.reshape(-1,28*28).shape) #for image origin is upper left \n",
        "print(x_train.reshape(-1,14*14).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_e9Vb4USKSO",
        "outputId": "5eb7508c-2a1a-428f-f068-61177800302c"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 784])\n",
            "torch.Size([240000, 196])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[:3] #2D array, basically a matrix, can be fetched into mlp architechture"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXpu3dVUSt3w",
        "outputId": "5036fc7d-5e49-4ff6-e8d0-a7f92f67ec81"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test = torch.load(\"test.pt\")"
      ],
      "metadata": {
        "id": "qCcmixbsTwNY"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = x_test.reshape(-1,28*28)"
      ],
      "metadata": {
        "id": "yXpQf3fIUDCH"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "Jo5cQPFjUHjl"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#supplying the image into mlp, its mandatory to supply as tensors not as array, here it is already tensors, but if not convert it\n",
        "#Tensordataset is just to make a sequence of all dataset, (like stack) so that GPU can be called , nice structure understandable by torch platform\n",
        "train_loader = DataLoader(TensorDataset(x_train.float(),y_train),\n",
        "                                       batch_size=64,shuffle = True)\n",
        "#shuffling is only required for training\n",
        "#tensor is not good dealing with integer, must be converted to float\n",
        "test_loader = DataLoader(TensorDataset(x_test.float(),y_test),\n",
        "                                      batch_size = 64,shuffle = False)"
      ],
      "metadata": {
        "id": "9YFjI3FAUcTS"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.nn.modules import dropout"
      ],
      "metadata": {
        "id": "R2GDBTqpXXSZ"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.tensor(array) when to convert the pic from memory into tensor"
      ],
      "metadata": {
        "id": "f0Ve7hI0WfKa"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNIST_DNN(nn.Module): #nn.module its the class, all the layers,activation are inheriting\n",
        "  def __init__(self):\n",
        "    super(MNIST_DNN,self).__init__() #this line linkds MNIST_DNN to nn.module by calling __init__()\n",
        "    self.h1 = nn.Linear(in_features=28*28,out_features=512) #linear means here dense in torch like dense in tensorflow\n",
        "    self.h2 = nn.Linear(in_features=512,out_features=256)\n",
        "    self.bn = nn.BatchNorm1d(num_features=256) #1D array Iam supplying, so 1D batchnormalization, if I have to supply a pic, 2D, then it will be 2D\n",
        "    self.h3 = nn.Linear(in_features=256,out_features=128)\n",
        "    self.dropout = nn.Dropout(p=0.40) #at random 30 percent will be dropout between h3 and h4 , to make model model robust, for regulazation we dropout\n",
        "    self.h4 = nn.Linear(in_features=128,out_features=32)\n",
        "    self.out = nn.Linear(in_features=32,out_features=10) #dont shrink less than 10(10 classes are there, that will be severely underfitting)\n",
        "\n",
        "  # def forward(self,x):\n",
        "  #   x = self.h1(x)\n",
        "  #   x = F.relu(x)\n",
        "  #   x = self.dropout(x)  #no parameter for dropout\n",
        "\n",
        "  #   x = F.relu(self.h2(x))\n",
        "\n",
        "  #   x = self.bn(x) #for initialization of bn , two parametres gamma and beta so, initialize every time\n",
        "  #   x = F.relu(self.h3(x))\n",
        "  #   x = self.dropout(x)\n",
        "\n",
        "  #   x = F.relu(self.h4())\n",
        "\n",
        "  #   x = F.relu(self.out(x))\n",
        "  #   #x = torch.softmax(x,dim=1)\n",
        "\n",
        "  #   return x\n",
        "  def forward(self,x):\n",
        "    x=self.h1(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.dropout(x)\n",
        "    x=F.relu(self.h2(x))\n",
        "\n",
        "    x=self.bn(x)\n",
        "    x=F.relu(self.h3(x))\n",
        "    x=self.dropout(x)\n",
        "\n",
        "    x=F.relu(self.h4(x))\n",
        "    x=self.dropout(x)\n",
        "\n",
        "    x=F.relu(self.out(x))\n",
        "    #x=torch.softmax(x,dim=1)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "9KLu3Ut5Xsp6"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_DNN =  MNIST_DNN()"
      ],
      "metadata": {
        "id": "dHvzgQv0feWQ"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(model_DNN.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo81JWi8gRhJ",
        "outputId": "263a8d7a-6ab3-4738-fafc-0bd65215de89"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.0088, -0.0279, -0.0019,  ..., -0.0154,  0.0204,  0.0213],\n",
              "         [ 0.0158, -0.0286,  0.0203,  ...,  0.0134,  0.0041, -0.0227],\n",
              "         [-0.0024,  0.0060,  0.0184,  ...,  0.0016, -0.0079, -0.0352],\n",
              "         ...,\n",
              "         [-0.0199,  0.0132,  0.0257,  ..., -0.0169,  0.0022, -0.0096],\n",
              "         [-0.0169,  0.0026, -0.0276,  ...,  0.0001, -0.0063,  0.0086],\n",
              "         [ 0.0262,  0.0142,  0.0294,  ..., -0.0185, -0.0164,  0.0183]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([ 0.0213, -0.0340,  0.0200, -0.0198, -0.0231,  0.0176, -0.0031,  0.0189,\n",
              "         -0.0120, -0.0117,  0.0191,  0.0257, -0.0356, -0.0312,  0.0175,  0.0233,\n",
              "          0.0303,  0.0305,  0.0171,  0.0212, -0.0252, -0.0238, -0.0316,  0.0270,\n",
              "          0.0299, -0.0219, -0.0127,  0.0334,  0.0280,  0.0144, -0.0175, -0.0314,\n",
              "         -0.0133, -0.0172, -0.0092,  0.0030, -0.0317, -0.0007, -0.0312,  0.0058,\n",
              "          0.0259,  0.0227,  0.0168, -0.0127,  0.0307,  0.0314, -0.0213,  0.0013,\n",
              "         -0.0167, -0.0130,  0.0174, -0.0212, -0.0147,  0.0262,  0.0151, -0.0216,\n",
              "          0.0057, -0.0200, -0.0042,  0.0138,  0.0251,  0.0246,  0.0205,  0.0247,\n",
              "         -0.0288,  0.0267, -0.0279,  0.0014,  0.0039,  0.0347,  0.0171, -0.0109,\n",
              "          0.0336, -0.0207,  0.0025,  0.0106,  0.0115, -0.0015,  0.0208,  0.0336,\n",
              "          0.0334,  0.0137, -0.0357, -0.0092, -0.0262, -0.0319, -0.0154,  0.0117,\n",
              "          0.0108,  0.0278, -0.0326, -0.0214, -0.0222, -0.0274, -0.0021,  0.0100,\n",
              "         -0.0039,  0.0175, -0.0203, -0.0215,  0.0222, -0.0258, -0.0195, -0.0335,\n",
              "         -0.0041, -0.0177, -0.0259,  0.0186,  0.0113,  0.0061, -0.0134,  0.0194,\n",
              "          0.0151,  0.0096,  0.0213,  0.0263,  0.0123,  0.0146, -0.0305,  0.0141,\n",
              "         -0.0085, -0.0229,  0.0182, -0.0355,  0.0138,  0.0032, -0.0210,  0.0117,\n",
              "         -0.0314, -0.0187,  0.0152,  0.0330,  0.0325, -0.0127, -0.0177,  0.0045,\n",
              "          0.0286,  0.0232, -0.0224, -0.0342, -0.0021, -0.0070, -0.0069,  0.0244,\n",
              "          0.0116,  0.0193, -0.0194, -0.0332, -0.0295,  0.0345, -0.0151, -0.0132,\n",
              "         -0.0334, -0.0003, -0.0341, -0.0298, -0.0325,  0.0314,  0.0302, -0.0087,\n",
              "          0.0263, -0.0036,  0.0125, -0.0194, -0.0261, -0.0024, -0.0104, -0.0094,\n",
              "          0.0169,  0.0341,  0.0240,  0.0014,  0.0351,  0.0264,  0.0264,  0.0137,\n",
              "          0.0171, -0.0157,  0.0209, -0.0003,  0.0242, -0.0084,  0.0051, -0.0325,\n",
              "         -0.0075, -0.0177,  0.0237, -0.0345,  0.0060,  0.0124,  0.0150, -0.0156,\n",
              "          0.0076, -0.0127,  0.0226,  0.0316,  0.0322,  0.0141, -0.0227,  0.0135,\n",
              "         -0.0098,  0.0134,  0.0199, -0.0106,  0.0185, -0.0105,  0.0252,  0.0238,\n",
              "          0.0311,  0.0298,  0.0340, -0.0303,  0.0146, -0.0100,  0.0271, -0.0003,\n",
              "          0.0107,  0.0298, -0.0018, -0.0071,  0.0087, -0.0130, -0.0083,  0.0278,\n",
              "          0.0239, -0.0298, -0.0328,  0.0169, -0.0049,  0.0212, -0.0196, -0.0215,\n",
              "         -0.0288,  0.0298,  0.0240, -0.0159,  0.0040, -0.0312,  0.0329, -0.0211,\n",
              "          0.0250,  0.0159, -0.0235, -0.0038,  0.0342,  0.0333, -0.0040,  0.0227,\n",
              "          0.0329, -0.0288,  0.0238,  0.0059, -0.0112,  0.0076, -0.0275,  0.0223,\n",
              "         -0.0245, -0.0066,  0.0161, -0.0232, -0.0233, -0.0239, -0.0112,  0.0187,\n",
              "          0.0011,  0.0344,  0.0268, -0.0105,  0.0294,  0.0197, -0.0195, -0.0266,\n",
              "          0.0248,  0.0205,  0.0195,  0.0073, -0.0150,  0.0335, -0.0202, -0.0274,\n",
              "         -0.0273, -0.0082,  0.0229,  0.0158, -0.0234,  0.0190,  0.0225, -0.0303,\n",
              "         -0.0068,  0.0104,  0.0141,  0.0282, -0.0251, -0.0290,  0.0102,  0.0145,\n",
              "          0.0193, -0.0223,  0.0027, -0.0153, -0.0085, -0.0322,  0.0287, -0.0128,\n",
              "          0.0296,  0.0052, -0.0129,  0.0144,  0.0222,  0.0093,  0.0088,  0.0068,\n",
              "          0.0339, -0.0102,  0.0103,  0.0103, -0.0250, -0.0222, -0.0143, -0.0227,\n",
              "          0.0154, -0.0339,  0.0159,  0.0036,  0.0185,  0.0180, -0.0222,  0.0062,\n",
              "         -0.0096,  0.0100, -0.0010,  0.0216,  0.0256,  0.0312, -0.0028, -0.0302,\n",
              "          0.0257, -0.0017, -0.0285, -0.0041, -0.0148,  0.0350, -0.0116, -0.0099,\n",
              "          0.0301, -0.0232, -0.0058,  0.0244,  0.0260, -0.0316,  0.0352,  0.0094,\n",
              "         -0.0116,  0.0060,  0.0327,  0.0273, -0.0173, -0.0283, -0.0237,  0.0213,\n",
              "         -0.0110,  0.0014, -0.0008,  0.0066, -0.0108, -0.0011, -0.0313, -0.0039,\n",
              "          0.0270,  0.0087, -0.0276, -0.0138,  0.0139, -0.0034,  0.0221,  0.0231,\n",
              "         -0.0081, -0.0256, -0.0027,  0.0062,  0.0337, -0.0227, -0.0199,  0.0213,\n",
              "          0.0114, -0.0052, -0.0052,  0.0092,  0.0243, -0.0336,  0.0077, -0.0164,\n",
              "         -0.0196, -0.0330,  0.0203, -0.0050, -0.0308,  0.0228,  0.0062,  0.0013,\n",
              "          0.0276,  0.0029, -0.0215, -0.0339,  0.0190,  0.0149, -0.0252,  0.0121,\n",
              "         -0.0035,  0.0036,  0.0219,  0.0067, -0.0355, -0.0016, -0.0349,  0.0176,\n",
              "         -0.0078, -0.0012, -0.0102,  0.0305, -0.0247, -0.0317, -0.0059,  0.0318,\n",
              "         -0.0206,  0.0070, -0.0159,  0.0251,  0.0220, -0.0273,  0.0224, -0.0281,\n",
              "         -0.0121, -0.0149, -0.0015,  0.0130,  0.0136, -0.0330,  0.0302,  0.0257,\n",
              "         -0.0136, -0.0345,  0.0027, -0.0195, -0.0191,  0.0062, -0.0160, -0.0308,\n",
              "          0.0009,  0.0340,  0.0035,  0.0093,  0.0279,  0.0033, -0.0004,  0.0256,\n",
              "         -0.0201, -0.0289,  0.0011, -0.0236,  0.0348,  0.0195, -0.0154,  0.0177,\n",
              "         -0.0074,  0.0324,  0.0163,  0.0330,  0.0032, -0.0197, -0.0345,  0.0245,\n",
              "         -0.0308,  0.0195,  0.0120, -0.0186,  0.0051,  0.0133,  0.0069, -0.0271,\n",
              "          0.0098,  0.0234,  0.0123, -0.0033, -0.0239,  0.0050, -0.0173, -0.0029,\n",
              "         -0.0254,  0.0267, -0.0176,  0.0271, -0.0021,  0.0194,  0.0067, -0.0068,\n",
              "          0.0121, -0.0095,  0.0020,  0.0085,  0.0225, -0.0011,  0.0218, -0.0228,\n",
              "         -0.0317, -0.0285, -0.0175,  0.0242, -0.0207, -0.0313, -0.0348,  0.0170],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([[-0.0319,  0.0209, -0.0134,  ..., -0.0171,  0.0075,  0.0123],\n",
              "         [-0.0283, -0.0057,  0.0382,  ..., -0.0388, -0.0080,  0.0285],\n",
              "         [ 0.0027,  0.0290, -0.0025,  ..., -0.0373,  0.0163, -0.0298],\n",
              "         ...,\n",
              "         [ 0.0003,  0.0274,  0.0438,  ...,  0.0322, -0.0019, -0.0326],\n",
              "         [-0.0100,  0.0357,  0.0045,  ...,  0.0435, -0.0403,  0.0087],\n",
              "         [-0.0315, -0.0356, -0.0256,  ...,  0.0262, -0.0373, -0.0396]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([ 0.0121, -0.0092, -0.0018, -0.0140, -0.0377, -0.0041, -0.0147,  0.0239,\n",
              "          0.0410,  0.0012, -0.0242, -0.0277,  0.0007, -0.0212, -0.0088,  0.0265,\n",
              "          0.0217, -0.0293,  0.0309,  0.0407, -0.0154,  0.0109, -0.0150, -0.0303,\n",
              "          0.0352, -0.0128,  0.0211, -0.0393, -0.0220, -0.0442, -0.0348, -0.0094,\n",
              "          0.0188, -0.0351,  0.0307, -0.0095,  0.0086,  0.0190, -0.0292, -0.0275,\n",
              "          0.0410, -0.0438, -0.0071,  0.0433,  0.0105, -0.0431, -0.0154,  0.0196,\n",
              "          0.0121, -0.0136, -0.0318,  0.0088,  0.0405,  0.0022,  0.0345,  0.0208,\n",
              "         -0.0152, -0.0280,  0.0148, -0.0309, -0.0380,  0.0041,  0.0098, -0.0184,\n",
              "         -0.0196,  0.0435,  0.0245,  0.0346,  0.0005,  0.0256, -0.0071, -0.0429,\n",
              "          0.0098,  0.0402,  0.0306,  0.0147, -0.0348, -0.0068,  0.0124,  0.0389,\n",
              "          0.0439, -0.0299, -0.0252,  0.0419, -0.0288, -0.0058, -0.0201,  0.0205,\n",
              "          0.0358, -0.0297,  0.0298, -0.0343,  0.0428,  0.0349,  0.0365,  0.0252,\n",
              "          0.0102, -0.0167, -0.0170,  0.0410,  0.0191, -0.0372,  0.0269,  0.0379,\n",
              "          0.0177,  0.0317,  0.0190, -0.0036, -0.0307, -0.0012, -0.0171,  0.0360,\n",
              "          0.0028,  0.0383,  0.0337, -0.0348,  0.0197,  0.0163, -0.0323, -0.0149,\n",
              "         -0.0423,  0.0377,  0.0121, -0.0379,  0.0103, -0.0097,  0.0074, -0.0270,\n",
              "         -0.0204,  0.0168, -0.0326, -0.0101,  0.0288, -0.0014,  0.0185,  0.0129,\n",
              "          0.0386,  0.0209,  0.0370,  0.0093,  0.0066, -0.0094,  0.0284,  0.0134,\n",
              "         -0.0121, -0.0376,  0.0367,  0.0419,  0.0165, -0.0438,  0.0341,  0.0164,\n",
              "          0.0311,  0.0441, -0.0236,  0.0256,  0.0092, -0.0434, -0.0374, -0.0386,\n",
              "         -0.0274, -0.0145, -0.0171, -0.0183,  0.0100,  0.0384, -0.0292,  0.0431,\n",
              "          0.0436,  0.0095, -0.0386, -0.0422, -0.0391,  0.0211,  0.0330,  0.0267,\n",
              "          0.0122, -0.0438, -0.0004,  0.0323,  0.0251, -0.0014,  0.0268, -0.0327,\n",
              "         -0.0092, -0.0016, -0.0440,  0.0241,  0.0282,  0.0324,  0.0063, -0.0021,\n",
              "         -0.0088,  0.0386, -0.0043, -0.0298, -0.0311, -0.0386,  0.0336,  0.0149,\n",
              "          0.0251,  0.0123,  0.0422,  0.0193,  0.0369,  0.0074,  0.0243, -0.0075,\n",
              "          0.0302,  0.0135,  0.0046,  0.0017,  0.0261, -0.0100, -0.0077,  0.0374,\n",
              "          0.0068, -0.0045,  0.0200, -0.0393, -0.0211, -0.0089, -0.0196,  0.0413,\n",
              "         -0.0386,  0.0020, -0.0228,  0.0435, -0.0086,  0.0156, -0.0189,  0.0070,\n",
              "         -0.0338,  0.0422, -0.0378,  0.0016,  0.0428,  0.0191, -0.0241, -0.0084,\n",
              "          0.0196, -0.0404,  0.0068, -0.0094,  0.0270,  0.0070, -0.0033, -0.0364,\n",
              "         -0.0221, -0.0076, -0.0240,  0.0420, -0.0390,  0.0286,  0.0414, -0.0228],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([[ 0.0261, -0.0419, -0.0204,  ...,  0.0008, -0.0077,  0.0111],\n",
              "         [-0.0339, -0.0503, -0.0333,  ..., -0.0380,  0.0215,  0.0393],\n",
              "         [ 0.0376, -0.0419,  0.0216,  ...,  0.0186,  0.0192,  0.0238],\n",
              "         ...,\n",
              "         [-0.0553,  0.0049,  0.0100,  ..., -0.0441,  0.0438, -0.0097],\n",
              "         [-0.0508,  0.0511,  0.0400,  ...,  0.0415, -0.0385,  0.0232],\n",
              "         [ 0.0189,  0.0562,  0.0625,  ...,  0.0318,  0.0495, -0.0142]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([-1.8752e-02, -6.0941e-02, -7.6265e-03, -4.4877e-02,  2.4280e-02,\n",
              "          1.4048e-02, -1.5008e-02,  2.3971e-02,  5.1612e-02,  3.1666e-02,\n",
              "         -4.6507e-02,  2.0313e-02, -2.6323e-02, -3.2009e-02, -3.2005e-02,\n",
              "          4.7664e-02, -2.5462e-02, -1.0639e-02, -3.7674e-02,  3.2042e-02,\n",
              "         -2.9935e-02, -8.6021e-03,  6.0323e-02,  2.2806e-02,  5.4833e-02,\n",
              "          4.4320e-02, -1.5411e-02,  1.2876e-02, -3.1594e-03,  5.7498e-02,\n",
              "         -3.7146e-02, -4.5689e-02,  2.5630e-02,  1.0641e-02, -3.1742e-02,\n",
              "          4.3757e-02,  8.4098e-03, -1.5561e-02,  2.3993e-03,  5.7537e-03,\n",
              "          2.8516e-02, -5.9781e-02, -5.4421e-02, -3.0114e-03,  4.8429e-02,\n",
              "         -3.5648e-02, -4.0268e-02, -4.0115e-02, -2.6047e-03, -4.6256e-02,\n",
              "          3.5211e-02,  1.8205e-02, -4.4022e-02,  3.4586e-02, -4.7679e-02,\n",
              "         -2.8938e-02,  1.2013e-02, -1.6331e-02, -2.5550e-02, -2.0755e-02,\n",
              "          5.9943e-02,  3.0279e-02, -5.7878e-02, -2.8746e-02,  4.4639e-02,\n",
              "          1.1357e-02,  2.8936e-02, -1.8092e-02, -2.7064e-02, -1.4237e-02,\n",
              "         -3.6301e-02, -5.9900e-02, -2.1547e-04, -6.1652e-02, -1.3716e-02,\n",
              "         -4.2299e-02,  2.1854e-02, -5.1511e-02, -6.1372e-02, -2.6900e-02,\n",
              "          5.2356e-02, -4.7764e-02, -2.2801e-02, -1.8155e-02,  2.0719e-04,\n",
              "          4.4048e-02, -3.8024e-02, -2.8496e-04,  6.0595e-02, -1.3966e-02,\n",
              "          2.9029e-02,  2.0728e-02,  1.5824e-02,  5.9723e-02, -4.3280e-02,\n",
              "          6.0805e-02, -3.3624e-02,  5.1631e-02, -4.7321e-02, -5.7237e-02,\n",
              "         -2.3850e-02,  2.9301e-02, -4.0073e-02,  5.7461e-02,  6.2116e-03,\n",
              "         -4.8416e-03,  6.6836e-03, -4.9688e-02, -2.7009e-02,  3.0519e-02,\n",
              "          2.2078e-03, -9.6961e-03,  5.7147e-02, -3.5140e-02,  6.2200e-03,\n",
              "         -7.8284e-03,  1.0543e-02, -3.1807e-02,  5.3994e-02,  5.4290e-02,\n",
              "         -3.5036e-02,  5.7988e-02,  3.5611e-02, -3.9734e-05, -6.1612e-03,\n",
              "          5.6460e-02, -6.1318e-03, -5.5333e-02], requires_grad=True), Parameter containing:\n",
              " tensor([[ 0.0510, -0.0052, -0.0326,  ..., -0.0178,  0.0296,  0.0541],\n",
              "         [-0.0178, -0.0717,  0.0511,  ...,  0.0221,  0.0088,  0.0054],\n",
              "         [ 0.0761,  0.0832,  0.0012,  ..., -0.0329,  0.0779, -0.0700],\n",
              "         ...,\n",
              "         [-0.0734, -0.0748, -0.0294,  ..., -0.0832,  0.0157,  0.0704],\n",
              "         [-0.0172,  0.0206,  0.0259,  ..., -0.0860, -0.0639, -0.0464],\n",
              "         [ 0.0203, -0.0480,  0.0537,  ..., -0.0857, -0.0456, -0.0745]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([-0.0329, -0.0635, -0.0004, -0.0417, -0.0008,  0.0162,  0.0860, -0.0357,\n",
              "         -0.0821,  0.0030, -0.0799,  0.0292,  0.0368,  0.0795, -0.0598,  0.0377,\n",
              "          0.0458, -0.0640, -0.0007, -0.0154, -0.0563, -0.0812, -0.0226, -0.0860,\n",
              "          0.0172, -0.0059,  0.0221,  0.0468,  0.0807, -0.0723,  0.0585, -0.0576],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([[ 0.0065,  0.0913,  0.1092,  0.1202,  0.0358, -0.0868,  0.0695, -0.0364,\n",
              "           0.1235, -0.1173,  0.0207,  0.1359,  0.0206,  0.1302,  0.0027,  0.1414,\n",
              "           0.0603,  0.0951,  0.1380,  0.1192,  0.0025,  0.1708,  0.0435,  0.1403,\n",
              "          -0.0515,  0.0022, -0.0749, -0.1606,  0.1477,  0.0394,  0.0305, -0.1449],\n",
              "         [-0.0152, -0.0076, -0.0415,  0.1590,  0.1291, -0.0735, -0.1746, -0.1650,\n",
              "          -0.1735, -0.1204,  0.1612, -0.0150,  0.0655, -0.0424,  0.1473,  0.0619,\n",
              "           0.0873, -0.0959,  0.0717,  0.1093, -0.0114,  0.1361,  0.1317, -0.0296,\n",
              "          -0.1567, -0.1139, -0.0114,  0.0644, -0.1682,  0.0613,  0.1558, -0.0736],\n",
              "         [ 0.0317,  0.0071, -0.1089, -0.1561,  0.0966, -0.1017, -0.0017,  0.0573,\n",
              "          -0.0541,  0.0581, -0.0394, -0.0242, -0.0239,  0.0633,  0.0900,  0.1035,\n",
              "           0.0334, -0.1069,  0.1565,  0.1727, -0.1674, -0.0934, -0.1531, -0.1619,\n",
              "           0.0219,  0.0538, -0.0639,  0.1556, -0.0147, -0.0818, -0.1338,  0.0233],\n",
              "         [ 0.1493,  0.1062, -0.0433, -0.1169,  0.0738,  0.0450, -0.0116, -0.0145,\n",
              "          -0.0256,  0.0830,  0.0617,  0.0217, -0.0707,  0.0967,  0.1199, -0.0306,\n",
              "           0.1707,  0.0663, -0.1196, -0.1578, -0.0599,  0.1688,  0.1710,  0.0550,\n",
              "          -0.1124, -0.1004, -0.0436, -0.1723, -0.1089, -0.1440, -0.0813, -0.1334],\n",
              "         [ 0.0529,  0.0119,  0.1070,  0.0068,  0.0316,  0.0355,  0.0417, -0.0769,\n",
              "           0.0671,  0.1044,  0.1625,  0.0112,  0.1337, -0.1109, -0.1536,  0.0863,\n",
              "          -0.1667,  0.1675, -0.0381,  0.0807, -0.1421,  0.0589, -0.0022,  0.1146,\n",
              "          -0.1405, -0.1541, -0.0886,  0.1470, -0.1280,  0.0984, -0.0757, -0.0099],\n",
              "         [ 0.0691,  0.1516, -0.1210,  0.0177,  0.1747, -0.0994, -0.0330, -0.0779,\n",
              "           0.0056,  0.0252, -0.1469, -0.0445, -0.0938, -0.0813,  0.0938, -0.1730,\n",
              "           0.1516, -0.0563, -0.1202, -0.0215,  0.0048, -0.0203,  0.0297, -0.1257,\n",
              "          -0.1351,  0.0793,  0.1159,  0.1762,  0.1295, -0.1128, -0.1318, -0.0485],\n",
              "         [ 0.1109, -0.0869, -0.1563, -0.1118, -0.1477,  0.1639,  0.0888, -0.0850,\n",
              "          -0.0036,  0.1570,  0.1668,  0.0301, -0.0929,  0.1437, -0.0024, -0.1047,\n",
              "          -0.1053, -0.1539,  0.1446, -0.1315,  0.1417, -0.0962, -0.1003,  0.0191,\n",
              "           0.1309,  0.0100, -0.0451, -0.1041, -0.0661, -0.1498, -0.0882,  0.1351],\n",
              "         [-0.1754, -0.0490,  0.1329,  0.1480, -0.0917,  0.1570,  0.1415,  0.1237,\n",
              "          -0.1458, -0.0194,  0.0252,  0.0133,  0.1280,  0.1401, -0.1638, -0.0103,\n",
              "           0.0644,  0.0182, -0.1475, -0.0947,  0.0580, -0.0395, -0.0320, -0.1253,\n",
              "          -0.0555, -0.0253, -0.1269,  0.1077, -0.0441, -0.1132, -0.1353, -0.1409],\n",
              "         [ 0.1011, -0.0556, -0.0462,  0.1549, -0.0871,  0.0184,  0.0669, -0.1323,\n",
              "          -0.1547,  0.0231,  0.0728, -0.0268,  0.0723,  0.1745,  0.1598, -0.0830,\n",
              "          -0.0519, -0.1043,  0.0515,  0.1668, -0.0861, -0.0521,  0.0477, -0.0156,\n",
              "          -0.0678,  0.0536, -0.0230,  0.0039, -0.0599, -0.0898,  0.1480,  0.0781],\n",
              "         [ 0.0259,  0.1632,  0.1142, -0.1759, -0.0831,  0.0966,  0.0371, -0.1121,\n",
              "           0.1739,  0.0752, -0.0741, -0.0413, -0.0625,  0.0775,  0.0571, -0.0161,\n",
              "          -0.0842,  0.0745,  0.0482,  0.1678,  0.0435,  0.1121,  0.0790, -0.1487,\n",
              "           0.0412,  0.1588,  0.1570, -0.1659, -0.0328,  0.0254, -0.0562, -0.1244]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([-0.0148, -0.0226,  0.1319,  0.1173, -0.1548, -0.0870, -0.1440,  0.1749,\n",
              "          0.1640, -0.0335], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(model_DNN.parameters(),lr = 0.001)"
      ],
      "metadata": {
        "id": "WLP-o6BHffzb"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cueXkXNno5I1",
        "outputId": "b7412c7e-9f83-40a2-d4ca-2c76521bad77"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_DNN = model_DNN.to(device) #model and data are shifting to gpu, massive parallelization can take place"
      ],
      "metadata": {
        "id": "gonqd6AWpD7x"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#it gives more flexibility in fit , learning arte itself can be chnaged, so torch is more flexible than tensorflow\n",
        "for epoch in range(30):\n",
        "  training_loss = 0.0\n",
        "  for batch, target in train_loader: #train_loader is a generator (bathc=mini batch,target = target)\n",
        "    batch=batch.to(device) #batch is a tensor,(not numpy) so can be shifted to gpu\n",
        "    target = target.to(device)\n",
        "    #print(batch.shape)\n",
        "    \n",
        "    #---- The Learning Phase ------#\n",
        "    opt.zero_grad() #removing all the calculated residual gradients after every batch, each batch is independent, gradients are calculated newly\n",
        "    output =  model_DNN(batch) #calculating output\n",
        "    loss = F.cross_entropy(output,target) #in torch just cross entropy\n",
        "    loss.backward() #gradients are calcuated, whether it is rmsProp, Adam anything\n",
        "    opt.step() #weights are upodated\n",
        "    #---- The Learning Phase ------#\n",
        "    training_loss += loss.item() #actual value of loss\n",
        "  \n",
        "  val_loss = 0.0\n",
        "  for val_batch, val_target in test_loader:\n",
        "    val_batch = val_batch.to(device)\n",
        "    val_target = val_target.to(device)\n",
        "    pred = model_DNN(val_batch)\n",
        "    loss_val = F.cross_entropy(pred,val_target)\n",
        "    val_loss += loss_val.item()\n",
        "\n",
        "  if (epoch+1) % 5 ==0:\n",
        "    print(f\"Training Loss: {training_loss}\")\n",
        "    print(f\"Test Loss: {val_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1mJvNv_pnVO",
        "outputId": "46df2ff8-8fab-44f7-bbb9-73a3035476d0"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 140.21595842950046\n",
            "Test Loss: 26.246933449059725\n",
            "Training Loss: 95.06415687222034\n",
            "Test Loss: 22.24703625042457\n",
            "Training Loss: 70.97013491694815\n",
            "Test Loss: 23.262531492044218\n",
            "Training Loss: 59.319071643345524\n",
            "Test Loss: 22.365305646701017\n",
            "Training Loss: 55.13681037322385\n",
            "Test Loss: 21.34860345936613\n",
            "Training Loss: 45.24363547667599\n",
            "Test Loss: 20.340063479874516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_pred_vals = model_DNN(x_test.float().to(device)).detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "Wy3PtHckw7qE"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.argmax(final_pred_vals,axis =1)"
      ],
      "metadata": {
        "id": "0NM8CxoCzixx"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from  sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "0b9AtXGRzoV4"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(preds,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCIThXNbzx5R",
        "outputId": "ddfd1823-16da-44a4-e1c0-a3934387828f"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 962,    0,    1,    1,    0,    3,    4,    0,    0,    1],\n",
              "       [   0, 1123,    1,    0,    1,    1,    2,    0,    0,    3],\n",
              "       [   3,    1, 1014,    5,    1,    0,    0,    8,    4,    1],\n",
              "       [   1,    1,    6,  994,    0,   26,    1,    3,    5,    9],\n",
              "       [   1,    1,    1,    0,  957,    0,    4,    2,    2,    7],\n",
              "       [   2,    0,    0,    1,    0,  844,    5,    0,    3,    2],\n",
              "       [   0,    1,    0,    0,    7,    4,  937,    0,    0,    1],\n",
              "       [   4,    1,    5,    4,    1,    0,    1, 1001,    4,    9],\n",
              "       [   5,    7,    3,    4,    2,   12,    4,    9,  954,   11],\n",
              "       [   2,    0,    1,    1,   13,    2,    0,    5,    2,  965]])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(preds,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJvSumv8144R",
        "outputId": "d58d3494-0fcc-4733-ca03-f3973a283359"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9751"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchsummary"
      ],
      "metadata": {
        "id": "gryS8x_y185r"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torchsummary.summary(model_DNN,input_size=(784,)) #more no the parameters, more complex model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i-iOz_M294U",
        "outputId": "140c909c-430d-44f5-fbea-024164f3afbc"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 512]         401,920\n",
            "           Dropout-2                  [-1, 512]               0\n",
            "            Linear-3                  [-1, 256]         131,328\n",
            "       BatchNorm1d-4                  [-1, 256]             512\n",
            "            Linear-5                  [-1, 128]          32,896\n",
            "           Dropout-6                  [-1, 128]               0\n",
            "            Linear-7                   [-1, 32]           4,128\n",
            "           Dropout-8                   [-1, 32]               0\n",
            "            Linear-9                   [-1, 10]             330\n",
            "================================================================\n",
            "Total params: 571,114\n",
            "Trainable params: 571,114\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 2.18\n",
            "Estimated Total Size (MB): 2.20\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#in case of cnn, no of parameters will be drastically down. "
      ],
      "metadata": {
        "id": "Bn9ilOVA3Iht"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}